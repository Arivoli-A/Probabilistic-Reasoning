{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical language modeling\n",
    "In this experiment, we look into the unigram and bigram model - its performance and disadvantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file hw4_vocab.txt contains a list of 500 tokens, corresponding to words, punctuation symbols, and other textual markers.\n",
    "\n",
    "The file hw4_unigram.txt contains the counts of each of these tokens in a large text corpus of Wall Street Journal articles.  The corpus consisted of roughly 3 million sentences.\n",
    "\n",
    "The file hw4_bigram.txt contains the counts of pairs of adjacent words in this same corpus.  Let count(w1,w2) denote the number of times that word w1 is followed by word w2.  The counts are stored in a simple three column format: \n",
    "\n",
    "  index(w1)  index(w2)  count(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word=pd.read_csv('hw4_vocab.txt',sep =' ',names =['Word'],quoting=csv.QUOTE_NONE)\n",
    "df_uni=pd.read_csv('hw4_unigram.txt',sep =' ',names =['Count'])\n",
    "df_bi=pd.read_csv('hw4_bigram.txt',sep ='\\t',names =['Index 1', 'Index 2','Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni = pd.concat([df_word,df_uni],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bi[['Index 1', 'Index 2']] -= 1 # Python index start from 0\n",
    "df_bi['Word 1'] = df_word['Word'][df_bi['Index 1']].values\n",
    "df_bi['Word 2'] = df_word['Word'][df_bi['Index 2']].values\n",
    "df_bi=df_bi[['Index 1','Index 2','Word 1','Word 2','Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimate of the unigram distribution $P_u(w)$ over words $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MILLION</td>\n",
       "      <td>169479</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>MORE</td>\n",
       "      <td>139728</td>\n",
       "      <td>0.001709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>MR.</td>\n",
       "      <td>117873</td>\n",
       "      <td>0.001442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>MOST</td>\n",
       "      <td>64424</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>MARKET</td>\n",
       "      <td>63807</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>MAY</td>\n",
       "      <td>59680</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>M.</td>\n",
       "      <td>57514</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>MANY</td>\n",
       "      <td>56968</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>MADE</td>\n",
       "      <td>45777</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>MUCH</td>\n",
       "      <td>42076</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>MAKE</td>\n",
       "      <td>42065</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>MONTH</td>\n",
       "      <td>36378</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>35740</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>MONTHS</td>\n",
       "      <td>33177</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>MY</td>\n",
       "      <td>32732</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>MONDAY</td>\n",
       "      <td>31233</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>MAJOR</td>\n",
       "      <td>30326</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>MILITARY</td>\n",
       "      <td>28785</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>MEMBERS</td>\n",
       "      <td>27478</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>MIGHT</td>\n",
       "      <td>22370</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>MEETING</td>\n",
       "      <td>21728</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>MUST</td>\n",
       "      <td>21791</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>ME</td>\n",
       "      <td>21551</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>MARCH</td>\n",
       "      <td>21242</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MAN</td>\n",
       "      <td>20677</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>MS.</td>\n",
       "      <td>19541</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>MINISTER</td>\n",
       "      <td>19605</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>MAKING</td>\n",
       "      <td>17310</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>17167</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>MILES</td>\n",
       "      <td>16841</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word   Count      prob\n",
       "53    MILLION  169479  0.002073\n",
       "68       MORE  139728  0.001709\n",
       "76        MR.  117873  0.001442\n",
       "120      MOST   64424  0.000788\n",
       "121    MARKET   63807  0.000780\n",
       "125       MAY   59680  0.000730\n",
       "129        M.   57514  0.000703\n",
       "130      MANY   56968  0.000697\n",
       "158      MADE   45777  0.000560\n",
       "177      MUCH   42076  0.000515\n",
       "179      MAKE   42065  0.000514\n",
       "202     MONTH   36378  0.000445\n",
       "208     MONEY   35740  0.000437\n",
       "226    MONTHS   33177  0.000406\n",
       "229        MY   32732  0.000400\n",
       "246    MONDAY   31233  0.000382\n",
       "255     MAJOR   30326  0.000371\n",
       "274  MILITARY   28785  0.000352\n",
       "286   MEMBERS   27478  0.000336\n",
       "355     MIGHT   22370  0.000274\n",
       "365   MEETING   21728  0.000266\n",
       "369      MUST   21791  0.000267\n",
       "373        ME   21551  0.000264\n",
       "374     MARCH   21242  0.000260\n",
       "384       MAN   20677  0.000253\n",
       "402       MS.   19541  0.000239\n",
       "403  MINISTER   19605  0.000240\n",
       "459    MAKING   17310  0.000212\n",
       "472      MOVE   17167  0.000210\n",
       "478     MILES   16841  0.000206"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum = df_uni['Count'].sum()\n",
    "df_uni['prob']=df_uni['Count']/total_sum\n",
    "df_uni[df_uni['Word'].str.startswith('M')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ten most likely words to follow the word 'THE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index 1</th>\n",
       "      <th>Index 2</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Count</th>\n",
       "      <th>net count</th>\n",
       "      <th>p_w2_w1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>THE</td>\n",
       "      <td>&lt;UNK&gt;</td>\n",
       "      <td>2371132</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.615020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>THE</td>\n",
       "      <td>U.</td>\n",
       "      <td>51556</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.013372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>THE</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>45186</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.011720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>THE</td>\n",
       "      <td>COMPANY</td>\n",
       "      <td>44949</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>THE</td>\n",
       "      <td>NEW</td>\n",
       "      <td>36439</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.009451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>3</td>\n",
       "      <td>183</td>\n",
       "      <td>THE</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>33435</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.008672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>THE</td>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>26230</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>THE</td>\n",
       "      <td>NINETEEN</td>\n",
       "      <td>25641</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.006651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>THE</td>\n",
       "      <td>SAME</td>\n",
       "      <td>24239</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.006287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>THE</td>\n",
       "      <td>TWO</td>\n",
       "      <td>23752</td>\n",
       "      <td>3855375</td>\n",
       "      <td>0.006161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index 1  Index 2 Word 1      Word 2    Count  net count   p_w2_w1\n",
       "993         3        0    THE       <UNK>  2371132    3855375  0.615020\n",
       "1058        3       69    THE          U.    51556    3855375  0.013372\n",
       "1064        3       78    THE       FIRST    45186    3855375  0.011720\n",
       "1060        3       72    THE     COMPANY    44949    3855375  0.011659\n",
       "1050        3       60    THE         NEW    36439    3855375  0.009451\n",
       "1165        3      183    THE      UNITED    33435    3855375  0.008672\n",
       "1086        3      102    THE  GOVERNMENT    26230    3855375  0.006803\n",
       "1029        3       38    THE    NINETEEN    25641    3855375  0.006651\n",
       "1282        3      307    THE        SAME    24239    3855375  0.006287\n",
       "1014        3       22    THE         TWO    23752    3855375  0.006161"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bi['net count'] = df_bi.groupby('Index 1')['Count'].transform('sum')\n",
    "df_bi['p_w2_w1']=df_bi['Count']/df_bi['net count']\n",
    "df_bi[df_bi['Word 1'] == 'THE'].sort_values(by=['p_w2_w1'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_likelihood(sent,df_U):\n",
    "    sent_list=sent.split()\n",
    "    sent_list = [word.upper() for word in sent_list]\n",
    "\n",
    "    # Filter the DataFrame to include only words in sent_list\n",
    "    filtered_df = df_U[df_U['Word'].isin(sent_list)]\n",
    "\n",
    "    # Create a categorical type for ordering\n",
    "    filtered_df['Word'] = pd.Categorical(filtered_df['Word'], categories=sent_list, ordered=True)\n",
    "\n",
    "    # Sort the filtered DataFrame based on the ordered categorical 'Word'\n",
    "    sorted_filtered_df = filtered_df.sort_values('Word').reset_index(drop=True)\n",
    "    \n",
    "    print(sorted_filtered_df)\n",
    "    \n",
    "    prob_vec=sorted_filtered_df['prob'].values\n",
    "    \n",
    "    return prob_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_likelihood(sent,df_B):\n",
    "    sent_list=sent.split()\n",
    "    sent_list = [word.upper() for word in sent_list]\n",
    "    sent_list.insert(0,'<s>')\n",
    "    \n",
    "    sent_list_prior = sent_list[:-1]  # Removes first element\n",
    "    sent_list_follow = sent_list[1:] # Removes last element\n",
    "    \n",
    "    #combined_mask = pd.Series([False] * len(df_B))\n",
    "    prob_vec = []\n",
    "    for i in list(range(len(sent_list)-1)):\n",
    "        current_mask = (df_B['Word 1'] == sent_list_prior[i]) & (df_B['Word 2'] == sent_list_follow[i])\n",
    "        print(df_B[current_mask].values)\n",
    "        if(not current_mask.any()):\n",
    "            prob_vec.append(1e-10)  # Probability smaller than smallest available in the training\n",
    "            continue   \n",
    "        #combined_mask = combined_mask | current_mask\n",
    "        prob_vec.append(df_B[current_mask]['p_w2_w1'].values[0])\n",
    " \n",
    "    return np.array(prob_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the sentence “The stock market fell by one hundred points last week”. Which model yields the highest log-likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1='The stock market fell by one hundred points last week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Word    Count      prob\n",
      "0      THE  3855375  0.047152\n",
      "1    STOCK    54645  0.000668\n",
      "2   MARKET    63807  0.000780\n",
      "3     FELL    21634  0.000265\n",
      "4       BY   341800  0.004180\n",
      "5      ONE   491054  0.006006\n",
      "6  HUNDRED   328791  0.004021\n",
      "7   POINTS    18060  0.000221\n",
      "8     LAST    94889  0.001161\n",
      "9     WEEK    46795  0.000572\n",
      "\n",
      "The unigram model log likelihood is -64.50944034364878\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe unigram model log likelihood is',sum(np.log(unigram_likelihood(s1,df_uni))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 '<s>' 'THE' 479427 3021866 0.15865263383617936]]\n",
      "[[3 132 'THE' 'STOCK' 8982 3855375 0.0023297344616282465]]\n",
      "[[132 121 'STOCK' 'MARKET' 5648 54645 0.10335803824686614]]\n",
      "[[121 376 'MARKET' 'FELL' 135 63807 0.0021157553246509003]]\n",
      "[[376 25 'FELL' 'BY' 467 21634 0.021586391790699825]]\n",
      "[[25 16 'BY' 'ONE' 2795 341800 0.008177296664716208]]\n",
      "[[16 26 'ONE' 'HUNDRED' 102660 491054 0.2090605106566691]]\n",
      "[[26 439 'HUNDRED' 'POINTS' 200 328791 0.0006082891563333546]]\n",
      "[[439 88 'POINTS' 'LAST' 103 18060 0.005703211517165006]]\n",
      "[[88 155 'LAST' 'WEEK' 15554 94889 0.1639178408456196]]\n",
      "\n",
      "The bigram model log likelihood is -40.91813213378977\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe bigram model log likelihood is',sum(np.log(bigram_likelihood(s1,df_bi))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the bigram model yields the highest log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the sentence “The sixteen officials sold fire insurance”. Which pairs of adjacent words in this sentence are not observed in the training corpus? What effect does this have on the log-likelihood from the bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2='The sixteen officials sold fire insurance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word    Count      prob\n",
      "0        THE  3855375  0.047152\n",
      "1    SIXTEEN    16540  0.000202\n",
      "2  OFFICIALS    54572  0.000667\n",
      "3       SOLD    16573  0.000203\n",
      "4       FIRE    17691  0.000216\n",
      "5  INSURANCE    17019  0.000208\n",
      "\n",
      "The unigram model log likelihood is -44.291934473132606\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe unigram model log likelihood is',sum(np.log(unigram_likelihood(s2,df_uni))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 '<s>' 'THE' 479427 3021866 0.15865263383617936]]\n",
      "[[3 498 'THE' 'SIXTEEN' 881 3855375 0.0002285121421392212]]\n",
      "[]\n",
      "[[133 499 'OFFICIALS' 'SOLD' 5 54572 9.162207725573554e-05]]\n",
      "[]\n",
      "[[443 488 'FIRE' 'INSURANCE' 54 17691 0.003052399525182296]]\n",
      "\n",
      "The bigram model log likelihood is -71.36632679534989\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe bigram model log likelihood is',sum(np.log(bigram_likelihood(s2,df_bi))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairs {'SIXTEEN','OFFICIALS'} and {'SOLD','FIRE'} are not present in the database. Since these pairs are not observed in the training corpus, ideally 0 probability must be assigned, but it leads to $-\\infty$ likelihood. To avoid that, a very small probability of $10^{-10}$ is assigned to each pair. Since these two pairs are not observed, the bigram model assigs very less log likelihood to the sentence as compared to the unigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture model\n",
    "Consider the so-called mixture model that predicts words from a weighted interpolation of the unigram\n",
    "and bigram models: $$P_m(w′|w) = \\lambda P_u(w′) + (1 − \\lambda)P_b(w′|w)$$ where $\\lambda \\in [0, 1]$. Compute and plot the value of the log-likelihood as a function of the parameter $\\lambda \\in [0, 1]$. From your results, deduce the optimal value of λ to two significant digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_likelihood(sent,df_U,df_B):\n",
    "    \n",
    "    prob_vec_uni= unigram_likelihood(sent,df_U)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    prob_vec_bi = bigram_likelihood(sent,df_B)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    prob_mix = []\n",
    "    \n",
    "    lam_vec = np.linspace(0,1,101)\n",
    "    \n",
    "    for lam in lam_vec :\n",
    "        prob_vec_mix = lam*prob_vec_uni+(1-lam)*prob_vec_bi\n",
    "        prob_mix.append(sum(np.log(prob_vec_mix)))\n",
    "  \n",
    "    plt.plot(lam_vec,np.transpose(prob_mix))\n",
    "    plt.title('Log likelihood of mixture model as a function of $\\lambda$')  # Title of the plot\n",
    "    plt.xlabel('$\\lambda$')  # Label for x-axis\n",
    "    plt.ylabel('log-likelihood')  # Label for y-axis\n",
    "    plt.grid()  # Show grid\n",
    "    plt.show()  # Display the plot\n",
    "    \n",
    "    max_ind=np.argmax(prob_mix)\n",
    "    max_lam=lam_vec[max_ind]\n",
    "        \n",
    "    print('The maximum log likelihood for mixture model is',prob_mix[max_ind],', happens at \\u03BB =',max_lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word    Count      prob\n",
      "0        THE  3855375  0.047152\n",
      "1    SIXTEEN    16540  0.000202\n",
      "2  OFFICIALS    54572  0.000667\n",
      "3       SOLD    16573  0.000203\n",
      "4       FIRE    17691  0.000216\n",
      "5  INSURANCE    17019  0.000208\n",
      "\n",
      "\n",
      "[[1 3 '<s>' 'THE' 479427 3021866 0.15865263383617936]]\n",
      "[[3 498 'THE' 'SIXTEEN' 881 3855375 0.0002285121421392212]]\n",
      "[]\n",
      "[[133 499 'OFFICIALS' 'SOLD' 5 54572 9.162207725573554e-05]]\n",
      "[]\n",
      "[[443 488 'FIRE' 'INSURANCE' 54 17691 0.003052399525182296]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum log likelihood for mixture model is -42.96416395341745 , happens at λ = 0.65\n"
     ]
    }
   ],
   "source": [
    "mixture_likelihood(s2,df_uni,df_bi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
